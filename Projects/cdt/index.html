<!doctype html>
<html>
    <head>
        <title>Projects - Joel Staggs</title>
        <style>

        </style>
        <link rel="stylesheet" href="../../stylesheet.css">
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    </head>
<body>
    <div class="jumbotron jumbotron-fluid bg-white">
        <div class="container">
          <h1 class="display-6">Joel Staggs</h1>
          <p >Software Developer</p>
          <nav class="navbar navbar-fluid navbar-expand-lg navbar-light bg-dark">
            <a class="navbar-brand text-white" href="../../index.html">Home</a>
            <a class="navbar-brand text-white" href="../../about.html">About</a>
            <a class="navbar-brand text-white" href="../index.html">Projects</a>
            <a class="navbar-brand text-white" href="#">Resume</a>
          </nav>
          <!--End of Nav-->
          
        </div>
        <div class="jumbotron bg-white">
          <div class="row">
            <div class="col-md-10 offset-md-1 col-12">
          <h1 class="display-4 ">Optimal Continuous Decision Tree</h1>
        </div>
      </div>
            <div class="row">
            <div class="col-md-8 offset-md-2 col-12">
            <p class="lead">
              This program uses entropy, a measure of uncertainty, to make optimal conclusions regarding a dataset.
              The tree is built using labelled training data, subtrees are created by splitting tables in a way that
              reduces entropy of labels the most (Minimized entropy can also be written as maximized information gain). This means that the minimal amount of splits will be required.
              An optimized tree conserves processing power when used, and can also minimize human interaction with its decision-making
              ability. This tree is continuous as our features are numerical. Our datasets are typical Iris flower data (four columns and a label), we need to find what attributes, and what values for those
              attributes will differentiate the flower species the most. For example, if splitting the data at a petal width of 1.5
              were to completely separate the different labels, that would likely be the best choice.
            </p>
          </div>
            <div class="col-md-4 offset-md-4 col-12">
              <img class="img-fluid" src="https://i.stack.imgur.com/6Yeu0.png" onclick="loadModal(this)">
            </div>
            <div class="col-md-4 offset-md-4 col-12">
              <div class="caption">
                <p>The entropy formula, we use this to quantify a table's uncertainty.</p>
              </div>
            </div>
          </div>

          <div class="row">
            <div class="col-md-8 offset-md-2 col-12">
            <p class="lead">
               We need to set up our objects to represent our tables. I chose to represent each table as an object,
               with references to parent and child tables. 
            </p>
          </div>
            <div class="col-md-4 offset-md-4 col-12">
              <img class="img-fluid" src="class.PNG" onclick="loadModal(this)">
            </div>
            <div class="col-md-4 offset-md-4 col-12">
              <div class="caption">
                <p>Object representation, this makes applying the tree to testing data very simple.</p>
              </div>
            </div>
          </div>

          <div class="row">
            <div class="col-md-8 offset-md-2 col-12">
            <p class="lead">
               Next, we calculate the maximum information gained, or minimal possible entropy for our base table, or tree root.
               Since we are using numeric data, we iterate through each column. Starting at a threshold of 0.0, we create two subtables:
               one contains all rows with a target column value of less than the threshold and the other contains all rows with a greater value.
               There are many ways to perform this operation; however, this is version is very straightforward to implement.
               Once we've found the best possible subtree configuration, we can repeat this operation on the subtrees themselves,
               or stop if the information gain is not sufficient.
            </p>
          </div>
            <div class="col-md-4 offset-md-4 col-12">
              <img class="img-fluid" src="igcalc.PNG" onclick="loadModal(this)">
            </div>
            <div class="col-md-4 offset-md-4 col-12">
              <div class="caption">
                <p>One method to find the optimal information gain for a table.</p>
              </div>
            </div>
          </div>

          <div class="row">
            <div class="col-md-8 offset-md-2 col-12">
            <p class="lead">
              This process can run recursively until there is no information gain possible. This does not mean all entropy has been removed,
              it simply means we cannot learn more using this method. This can be caused by outliers in the data, or by very similar samples
              of differing labels. In my implementation, I choose to decide a label based on whichever label is the majority of a leaf table. A minimum
              can also be set on the amount of information gained from splitting a table. This means the user can ignore some less common cases in
              order to maintain a cleaner tree or save processing time. This comes at the cost of accuracy, but can be useful if processing power
              is limited or a cleaner tree is needed.  
            </p>
          </div>
            <div class="col-md-4 offset-md-4 col-12">
              <img class="img-fluid" src="gain.PNG" onclick="loadModal(this)">
            </div>
            <div class="col-md-4 offset-md-4 col-12">
              <div class="caption">
                <p>Creating a new pair of subtables if there is sufficient information gain.</p>
              </div>
            </div>
            <div class="col-md-4 offset-md-4 col-12">
              <img class="img-fluid" src="nogain.PNG" onclick="loadModal(this)">
            </div>
            <div class="col-md-4 offset-md-4 col-12">
              <div class="caption">
                <p>What happens with no information can be gained from a split, I choose what label/category is in the majority.</p>
              </div>
            </div>
          </div>

          <div class="row">
            <div class="col-md-8 offset-md-2 col-12" onclick="loadModal(this)">
            <p class="lead">
              Next, we apply the testing data to our table. Since we stored our split information at each level of the tree,
              we can just step through the tree recursively, similarly to how we built it. 
            </p>
          </div>
            <div class="col-md-4 offset-md-4 col-12">
              <img class="img-fluid" src="testingTable.PNG" onclick="loadModal(this)">
            </div>
            <div class="col-md-4 offset-md-4 col-12">
              <div class="caption">
                <p>The final decision tree simply needs to split on attributes determined to be optimal.</p>
              </div>
            </div>
          </div>

          <div class="row">
            <div class="col-md-8 offset-md-2 col-12">
            <p class="lead">
              Finally, the table can be displayed to the DOM. I used Breadth first search to display the tables at their
              proper depth within the tree and an SVG layer to connect the tables with lines. In the image below, the top tree represents
              the initial tree calculated using entropy reduction. Colors are assigned corresponding to label majority within
              a terminal table. The second table is the placement of the testing data within the first table. They are the same, which means
              the same conclusions were mostly made on both trees. However, this is not a measure of accuracy, and one must be performed separately.
            </p>
          </div>
            <div class="col-md-4 offset-md-4 col-12">
              <img class="img-fluid" src="tree.png" onclick="loadModal(this)">
            </div>
            <div class="col-md-4 offset-md-4 col-12">
              <div class="caption">
                <p>Visualization of the tree, built using BFS with SVG connections.</p>
              </div>
            </div>
          </div>

          <div class="row">
            <div class="col-md-8 offset-md-2 col-12">
            <p class="lead">
              I was not provided the labels for this dataset; however, I was provided a program that would display my accuracy.
              This could be improved by changing criteria within tables with little to no information gain, but for now these results are sufficient.
              The code can be found <a href="ContinuousDecisionTree.php">here</a> (available on viewing page source). It includes code to read the files, so I kept it as a .PHP file.
              It can be run at <a href="https://cs.csubak.edu/~jstaggs/4450/ContinuousDecisionTree.php"> my CSUB site</a>.
              The <a href="DT_irisTraining.csv">training data</a> and <a href="DT_irisTesting.csv">testing data</a> are also available. 
            </p>
          </div>
            <div class="col-md-4 offset-md-4 col-12">
              <img class="img-fluid" src="output.PNG" onclick="loadModal(this)">
            </div>
            <div class="col-md-4 offset-md-4 col-12">
              <div class="caption">
                <p>Our final accuracy - 94%.</p>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="modalBg" id="modal" onclick="closeModal(this)">
        <div class="row h-100">
        <div class="align-self-center mx-auto d-block">
          <img id="modalImg" class="img-fluid" src="#">
        </div>
        </div>
      </div>

      
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    <script src="../../lib.js"></script>
</body>
</html>